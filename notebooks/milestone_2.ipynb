{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "hispanic-vatican",
   "metadata": {},
   "source": [
    "# DSCI 525 - Web and Cloud Computing\n",
    "\n",
    "# Milestone 2 - Group 8\n",
    "\n",
    "## Rachel Wong, Rui Wang, Daniel Ortiz, Santiago Rugeles Schoonewolff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conservative-uncle",
   "metadata": {},
   "source": [
    "Milestone 2: The purpose of this milestone is to move our data to the cloud and get comfortable working there."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "purple-license",
   "metadata": {},
   "source": [
    "## Milestone 2 checklist  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smoking-alert",
   "metadata": {},
   "source": [
    "- [ ] Setup your EC2 instance with JupyterHub.  \n",
    "- [ ] Install all necessary things needed in your UNIX server (amazon ec2 instance).\n",
    "- [ ] Setup your S3 bucket.\n",
    "- [ ] Move the data that you wrangled in your last milestone to s3.\n",
    "- [ ] Get the data from S3 in your notebook and make data ready for machine learning.\n",
    "\n",
    "**Keep in mind:**\n",
    "\n",
    "- _All services you use are in region Canada ca-central-1._\n",
    "\n",
    "- _Use only default VPC and subnet, also if not specified explicitly in instruction, leave those options as default when setting up an instance and s3._\n",
    "    \n",
    "- _No IP addresses are visible when you provide the screenshot._\n",
    "\n",
    "- _We want one single notebook for grading, and it's up to your discretion on how you do it. ***So only person in your group spins ```t2.xlarge```.***_\n",
    "\n",
    "- _Say something went wrong and you want to spin up another EC2 instance, then make sure you terminate the previous one._\n",
    "\n",
    "- _We will be choosing the storage to be ```Delete on Termination```, which means upon termination, stored data in your instance will be lost. Make sure you save any data to S3 and download the notebooks to your laptop so that next time you have your jupyterHub in a different instance, you can upload your notebook there._\n",
    "\n",
    "_***Outside of Milestone:*** If you are working as an individual to just practice setting up EC2 instances, make sure you select ```t2.micro``` instance and stick to other ```settings/instructions``` given in this milestone. I strongly recommend you spinning up your own instance and experimenting with the s3 bucket in doing something to get comfortable with AWS. But we won't be looking at it for a grading purpose._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "healthy-foster",
   "metadata": {},
   "source": [
    "### 1. Setup your EC2 instance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surrounded-beauty",
   "metadata": {},
   "source": [
    "rubric={correctness:20}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abandoned-swift",
   "metadata": {},
   "source": [
    "Follow the instructions shown during the lecture to set up your EC2 instance. You can use [this](https://tljh.jupyter.org/en/latest/install/amazon.html ) as your reference, but please make sure you follow the below instructions.\n",
    "\n",
    "1.1) Choose AMI \"Ubuntu Server 18.04 LTS (HVM), SSD Volume Type 64-bit (x86)\".\n",
    "\n",
    "1.2) Choose an Instance Type t2.xlarge.\n",
    "\n",
    "1.2) Make sure you go with the default VPC & subnet.\n",
    "\n",
    "1.4) Get the configuration code from step 7 in the above link and replace \"admin-user-name\"(remove < > as well) with your AWS IAM username.\n",
    "    \n",
    "1.5) Storage use Root with size 30 GB.\n",
    "    \n",
    "1.6) Add tag, enter \"Owner\" under the Key field. In the Value field in the Name row, give your IAM username.\n",
    "    \n",
    "1.7) Select an existing security group Name \"DSCI525.\"\n",
    "    \n",
    "1.8) Review page looks like [this](https://github.ubc.ca/MDS-2020-21/DSCI_525_web-cloud-comp_students/blob/master/images/1_out.png) before you launch the instance.\n",
    "    \n",
    "1.9) In the pop-up, \"Select an existing key pair or a new key pair.\" If you are setting up your cluster for the first time, click on create a new key pair and name it as your \"IAM user account\". Download the private key and keep it secure. Next time when you set up the EC2 instance, make sure you select \"Choose an existing keypair\" and choose the one you already made for you.\n",
    "    \n",
    "1.10) Search for your \"IAM user account\" under instances to see if it's running. Give it 15 - 20 min as even if it shows running, it will take more time to set up JupyterHub. So please wait...!\n",
    "    \n",
    "1.11) Check out the \"Connect\" button to determine how you can connect to the instance. Now you are given the DOOR access to the server, which we mentioned in our first class. :)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adverse-egypt",
   "metadata": {},
   "source": [
    "#### Please attach this screen shots from your group for grading.\n",
    "https://github.ubc.ca/MDS-2020-21/DSCI_525_web-cloud-comp_students/blob/master/images/1_result.png"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "given-gilbert",
   "metadata": {},
   "source": [
    "### 2. Setup your JupyterHub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pending-heath",
   "metadata": {},
   "source": [
    "rubric={correctness:20}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wrong-continuity",
   "metadata": {},
   "source": [
    "2.1) Under description, check for \"IPv4 Public IP\" and paste the IP address in your browser for your JupyterHub.\n",
    "\n",
    "2.2) Enter your \"IAM user account\" and use a strong password & note it down somewhere, as what you enter here will be the admin password.\n",
    "    \n",
    "2.3) In your JupyterHub, go to \"Control Panel\" --> \"admin.\" Here add other members of your group use their \"IAM user account\" and make them admins.\n",
    "    \n",
    "2.4) Check if other members can log in to the JupyterHub from their machines by giving them the URL to connect. Step 2.2 is applicable here for other members."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eight-bibliography",
   "metadata": {},
   "source": [
    "#### Please attach this screen shots from your group for grading\n",
    "I want to see all the group members here in this screenshot https://github.ubc.ca/MDS-2020-21/DSCI_525_web-cloud-comp_students/blob/master/images/2_result.png"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beneficial-handling",
   "metadata": {},
   "source": [
    "### 3. Setup the server "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "institutional-infection",
   "metadata": {},
   "source": [
    "rubric={correctness:20}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "saving-perry",
   "metadata": {},
   "source": [
    "3.1) Login in to the server (instance). The person who spins up the EC2 instance will only have access to the server as he only got the private key. If someone else wants to log in to that instance, you need to get hold of that private key (  Refer 1.10 ). Need to know more ? [Click here](https://github.ubc.ca/MDS-2020-21/DSCI_521_platforms-dsci_instructors/blob/master/lectures/7-ssh-filenames-project-organization.ipynb)\n",
    "\n",
    "3.2) Setup a common data folder to download data, and this folder should be accessible by all users in the JupyterHub. Following commands make a folder and make it accessible to everyone. Want to learn more about basic UNIX commands? [Click here](https://maker.pro/linux/tutorial/basic-linux-commands-for-beginners).\n",
    "\n",
    "```\n",
    "sudo mkdir -p /srv/data/my_shared_data_folder\n",
    "sudo chmod 777 /srv/data/my_shared_data_folder/\n",
    "```\n",
    "    \n",
    "3.3)(***OPTIONAL, no bonus points***) If you want a sharing notebook environment, then check out [this]( https://github.com/gutow/tljh_grp_utils). if you plan to do this, make sure you install the \"members\" package in your server run ```sudo apt-get install members```.\"\n",
    "\n",
    "3.4) Install AWS CLI. More details [here](https://docs.aws.amazon.com/cli/latest/userguide/install-cliv2-linux.html).\n",
    "\n",
    "_NOTE:We are installing this in our EC2 instance, but we can install this anywhere to interact with s3. Say you can install it in your local machine and move data to s3._\n",
    "\n",
    "    curl \"https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip\" -o \"awscliv2.zip\"\n",
    "    sudo apt install unzip\n",
    "    unzip awscliv2.zip\n",
    "    sudo ./aws/install\n",
    "    \n",
    "3.5) Setup your access key and secret. Do it from your [AWS console](https://console.aws.amazon.com/iam/home?#/security_credentials). Make sure you keep your \"Access key ID\" & secret key somewhere safe.\n",
    "\n",
    "3.6) Use these credentials to configure AWS CLI (aws configure). More details [here](https://docs.aws.amazon.com/cli/latest/userguide/cli-configure-quickstart.html). \"Default region\" and \"output format\" you can leave empty.\n",
    "\n",
    "3.7) AWS cli can be used to interact with a lot of services. Check this [out](https://docs.aws.amazon.com/cli/latest/reference/). To get a feel, we will use CLI to interact with s3 and wait for step 6."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "local-double",
   "metadata": {},
   "source": [
    "#### Please attach this screen shots from your group for grading\n",
    "\n",
    "Make sure you mask the IP address refer [here](https://www.anysoftwaretools.com/blur-part-picture-mac/).\n",
    "\n",
    "https://github.ubc.ca/MDS-2020-21/DSCI_525_web-cloud-comp_students/blob/master/images/3_result.png"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hispanic-proceeding",
   "metadata": {},
   "source": [
    "### 4. Get the data what we wrangled in our first milestone. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blank-manchester",
   "metadata": {},
   "source": [
    "You have to install the packages that are needed. Refer this TLJH [document]( https://tljh.jupyter.org/en/latest/howto/env/user-environment.html).Refer ```pip``` section.\n",
    "\n",
    "Don't forget to add option -E. This way, all packages that you install will be available to other users in your JupyterHub.\n",
    "These packages you must install and install other packages needed for your wrangling.\n",
    "\n",
    "    sudo -E pip install pandas\n",
    "    sudo -E pip install pyarrow\n",
    "    sudo -E pip install s3fs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "olive-document",
   "metadata": {},
   "source": [
    "As in the last milestone, we looked at getting the data transferred from Python to R, and we have different solutions. Henceforth, I uploaded the parquet file format, which we can use moving forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "biblical-formation",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/tljh/user/lib/python3.7/site-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (1.26.4) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "import glob\n",
    "import zipfile\n",
    "import requests\n",
    "from urllib.request import urlretrieve\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "permanent-muscle",
   "metadata": {},
   "source": [
    "Rememeber here we gave the folder that we created in Step 3.2 as we made it available for all the users in a group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "forbidden-specification",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary metadata\n",
    "article_id = 14226968  # this is the unique identifier of the article on figshare\n",
    "url = f\"https://api.figshare.com/v2/articles/{article_id}\"\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "output_directory = \"/srv/data/my_shared_data_folder/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "accessible-capability",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'is_link_only': False,\n",
       "  'name': 'allyears.csv.zip',\n",
       "  'supplied_md5': '9e046ac05ecd2c32a256a47dd1098b81',\n",
       "  'computed_md5': '9e046ac05ecd2c32a256a47dd1098b81',\n",
       "  'id': 26844650,\n",
       "  'download_url': 'https://ndownloader.figshare.com/files/26844650',\n",
       "  'size': 2405908113},\n",
       " {'is_link_only': False,\n",
       "  'name': 'individual_years.zip',\n",
       "  'supplied_md5': '921da748974b07b2a70bbfcc04535a77',\n",
       "  'computed_md5': '921da748974b07b2a70bbfcc04535a77',\n",
       "  'id': 26863682,\n",
       "  'download_url': 'https://ndownloader.figshare.com/files/26863682',\n",
       "  'size': 1896206676},\n",
       " {'is_link_only': False,\n",
       "  'name': 'combined_model_data.csv.zip',\n",
       "  'supplied_md5': '7638434c44a7d29cbb29fe200b4fd65d',\n",
       "  'computed_md5': '7638434c44a7d29cbb29fe200b4fd65d',\n",
       "  'id': 27515426,\n",
       "  'download_url': 'https://ndownloader.figshare.com/files/27515426',\n",
       "  'size': 821308997},\n",
       " {'is_link_only': False,\n",
       "  'name': 'combined_model_data_parti.parquet.zip',\n",
       "  'supplied_md5': '02f4e3df8d16580a02291de225072689',\n",
       "  'computed_md5': '02f4e3df8d16580a02291de225072689',\n",
       "  'id': 27520682,\n",
       "  'download_url': 'https://ndownloader.figshare.com/files/27520682',\n",
       "  'size': 519743915},\n",
       " {'is_link_only': False,\n",
       "  'name': 'combined_model_data.parquet',\n",
       "  'supplied_md5': 'ae63699ab21ffa8006559c6afbcd2271',\n",
       "  'computed_md5': 'ae63699ab21ffa8006559c6afbcd2271',\n",
       "  'id': 27520808,\n",
       "  'download_url': 'https://ndownloader.figshare.com/files/27520808',\n",
       "  'size': 565872005}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = requests.request(\"GET\", url, headers=headers)\n",
    "data = json.loads(response.text)  # this contains all the articles data, feel free to check it out\n",
    "files = data[\"files\"]             # this is just the data about the files, which is what we want\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "warming-principal",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_to_dl = [\"combined_model_data_parti.parquet.zip\"]  ## Please download the partitioned \n",
    "for file in files:\n",
    "    if file[\"name\"] in files_to_dl:\n",
    "        os.makedirs(output_directory, exist_ok=True)\n",
    "        urlretrieve(file[\"download_url\"], output_directory + file[\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "absolute-transaction",
   "metadata": {},
   "outputs": [],
   "source": [
    "with zipfile.ZipFile(os.path.join(output_directory, \"combined_model_data_parti.parquet.zip\"), 'r') as f:\n",
    "    f.extractall(output_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dense-matrix",
   "metadata": {},
   "source": [
    "### 5. Setup your S3 bucket and move data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "devoted-titanium",
   "metadata": {},
   "source": [
    "rubric={correctness:20}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valued-simulation",
   "metadata": {},
   "source": [
    "5.1) Get comfortable with S3 UI. Go from the AWS console.\n",
    "\n",
    "5.2) Create a bucket there. The name should be mds-s3-xxx. Replace xxx with your \"IAM user account\".\n",
    "\n",
    "5.3) All other options leave as it is. (Make sure AWS region is Canada).\n",
    "\n",
    "5.4) Create your first folder called \"output\".\n",
    "\n",
    "5.5) Move the \"observed_daily_rainfall_SYD.csv\" file from the Milestone1 data folder to your s3 bucket from your local computer. (it's a tiny file, so maybe you can easily use UI to upload).\n",
    "\n",
    "5.6) Moving the parquet file we downloaded in step 4 to S3 using the cli what we installed in step 3.7.\n",
    "Refer [this](https://docs.aws.amazon.com/cli/latest/userguide/cli-services-s3-commands.html#using-s3-commands-managing-objects-move) document and figure out yourself!\n",
    "    \n",
    "Hint: We are interested in the ```cp``` command. ```local``` is the directory path on our server."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "curious-terry",
   "metadata": {},
   "source": [
    "#### Please attach this screen shots from your group for grading\n",
    "\n",
    "Make sure it has 3 objects.\n",
    "\n",
    "https://github.ubc.ca/MDS-2020-21/DSCI_525_web-cloud-comp_students/blob/master/images/4_result.png"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "virgin-grenada",
   "metadata": {},
   "source": [
    "### 6. Wrangle the data in preparation for machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "realistic-burton",
   "metadata": {},
   "source": [
    "rubric={correctness:20}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "weighted-westminster",
   "metadata": {},
   "source": [
    "Our data currently covers all of NSW, but say that our client wants us to create a machine learning model to predict rainfall over Sydney only. There's a bit of wrangling that needs to be done for that:\n",
    "1. We need to query our data for only the rows that contain information covering Sydney\n",
    "2. We need to wrangle our data into a format suitable for training a machine learning model. That will require pivoting, resampling, grouping, etc.\n",
    "\n",
    "To train an ML algorithm we need it to look like this:\n",
    "\n",
    "||model-1_rainfall|model-2_rainfall|model-3_rainfall|...|observed_rainfall|\n",
    "|---|---|---|---|---|---|\n",
    "|0|0.12|0.43|0.35|...|0.31|\n",
    "|1|1.22|0.91|1.68|...|1.34|\n",
    "|2|0.68|0.29|0.41|...|0.57|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "available-execution",
   "metadata": {},
   "source": [
    "6.1) Get the data from s3\n",
    "\n",
    "6.2) First query for Sydney data and then drop the lat and lon columns (we don't need them).\n",
    "```\n",
    "syd_lat = -33.86\n",
    "syd_lon = 151.21\n",
    "```\n",
    "Expected shape ```(1150049, 2)```.\n",
    "\n",
    "6.3) Save this processed file to s3 for later use:\n",
    "\n",
    "  Save as a csv file ```ml_data_SYD.csv``` to ```s3://mds-s3-student96/output/```\n",
    "  expected shape ```(46020,26)``` - This includes all the models as columns and also adding additional column ```Observed``` loaded from ```observed_daily_rainfall_SYD.csv``` from s3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "pleased-samoa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.84 s, sys: 6.39 s, total: 14.2 s\n",
      "Wall time: 8.86 s\n"
     ]
    }
   ],
   "source": [
    "# Passing your credentials \n",
    "## IMPORTANT: make sure you dont include you secret and key when submitting the notebook\n",
    "aws_credentials ={\"key\": \"<use yours>\",\"secret\": \"<use yours>\"} ## dont include you secret and key when submitting the notebook\n",
    "df = pd.read_parquet(\"s3://mds-s3-student96/combined_model_data_parti.parquet\", storage_options=aws_credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "upper-track",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>lat_min</th>\n",
       "      <th>lat_max</th>\n",
       "      <th>lon_min</th>\n",
       "      <th>lon_max</th>\n",
       "      <th>rain (mm/day)</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1889-01-01 12:00:00</td>\n",
       "      <td>-35.439867</td>\n",
       "      <td>-33.574619</td>\n",
       "      <td>141.5625</td>\n",
       "      <td>143.4375</td>\n",
       "      <td>4.244226e-13</td>\n",
       "      <td>MPI-ESM-1-2-HAM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1889-01-02 12:00:00</td>\n",
       "      <td>-35.439867</td>\n",
       "      <td>-33.574619</td>\n",
       "      <td>141.5625</td>\n",
       "      <td>143.4375</td>\n",
       "      <td>4.217326e-13</td>\n",
       "      <td>MPI-ESM-1-2-HAM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1889-01-03 12:00:00</td>\n",
       "      <td>-35.439867</td>\n",
       "      <td>-33.574619</td>\n",
       "      <td>141.5625</td>\n",
       "      <td>143.4375</td>\n",
       "      <td>4.498125e-13</td>\n",
       "      <td>MPI-ESM-1-2-HAM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1889-01-04 12:00:00</td>\n",
       "      <td>-35.439867</td>\n",
       "      <td>-33.574619</td>\n",
       "      <td>141.5625</td>\n",
       "      <td>143.4375</td>\n",
       "      <td>4.251282e-13</td>\n",
       "      <td>MPI-ESM-1-2-HAM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1889-01-05 12:00:00</td>\n",
       "      <td>-35.439867</td>\n",
       "      <td>-33.574619</td>\n",
       "      <td>141.5625</td>\n",
       "      <td>143.4375</td>\n",
       "      <td>4.270161e-13</td>\n",
       "      <td>MPI-ESM-1-2-HAM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  time    lat_min    lat_max   lon_min   lon_max  \\\n",
       "0  1889-01-01 12:00:00 -35.439867 -33.574619  141.5625  143.4375   \n",
       "1  1889-01-02 12:00:00 -35.439867 -33.574619  141.5625  143.4375   \n",
       "2  1889-01-03 12:00:00 -35.439867 -33.574619  141.5625  143.4375   \n",
       "3  1889-01-04 12:00:00 -35.439867 -33.574619  141.5625  143.4375   \n",
       "4  1889-01-05 12:00:00 -35.439867 -33.574619  141.5625  143.4375   \n",
       "\n",
       "   rain (mm/day)            model  \n",
       "0   4.244226e-13  MPI-ESM-1-2-HAM  \n",
       "1   4.217326e-13  MPI-ESM-1-2-HAM  \n",
       "2   4.498125e-13  MPI-ESM-1-2-HAM  \n",
       "3   4.251282e-13  MPI-ESM-1-2-HAM  \n",
       "4   4.270161e-13  MPI-ESM-1-2-HAM  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### How the file looks like \n",
    "# shape of this file (62513863, 7), how it looks \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "engaged-crystal",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Do all your coding here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "square-mirror",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regular-graphic",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generic-prerequisite",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thermal-modeling",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "constitutional-peripheral",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "close-photographer",
   "metadata": {},
   "source": [
    "How the final file format looks like\n",
    "https://github.ubc.ca/MDS-2020-21/DSCI_525_web-cloud-comp_students/blob/master/images/finaloutput.png\n",
    "\n",
    "Shape ```(46020,26 )```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latin-charm",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "adapted-disco",
   "metadata": {},
   "source": [
    "(***OPTIONAL, no bonus points***) Want to check out how much time it will take to read a CSV file instead of parquet from s3?\n",
    "\n",
    "For that, upload the CSV file (```combined_model_data.csv.zip```\n",
    " )to S3 and try to read it instead of parquet. \n",
    " \n",
    " You probably will get the answer for **WHY** parquet? :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indonesian-mechanics",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
