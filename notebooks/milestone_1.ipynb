{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eligible-lease",
   "metadata": {},
   "source": [
    "# DSCI: 525 Milestone 1 - Group 8\n",
    "\n",
    "## Rachel Wong, Rui Wang, Daniel Ortiz, Santiago Rugeles Schoonewolff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cordless-template",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "further-spice",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import glob\n",
    "import zipfile\n",
    "import requests\n",
    "from urllib.request import urlretrieve\n",
    "import json\n",
    "import pandas as pd\n",
    "from memory_profiler import memory_usage\n",
    "\n",
    "# Dask\n",
    "import dask.dataframe as dd\n",
    "\n",
    "# pyarrow and feather\n",
    "import pyarrow.feather as feather\n",
    "import pyarrow.dataset as ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "swiss-convenience",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython\n",
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "golden-guard",
   "metadata": {},
   "source": [
    "### Downloading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "exotic-category",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary metadata\n",
    "article_id = 14096681  # unique identifier of the article on figshare\n",
    "url = f\"https://api.figshare.com/v2/articles/{article_id}\"\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "output_directory = \"figshare/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "martial-crest",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'is_link_only': False,\n",
       "  'name': 'daily_rainfall_2014.png',\n",
       "  'supplied_md5': 'fd32a2ffde300a31f8d63b1825d47e5e',\n",
       "  'computed_md5': 'fd32a2ffde300a31f8d63b1825d47e5e',\n",
       "  'id': 26579150,\n",
       "  'download_url': 'https://ndownloader.figshare.com/files/26579150',\n",
       "  'size': 58863},\n",
       " {'is_link_only': False,\n",
       "  'name': 'environment.yml',\n",
       "  'supplied_md5': '060b2020017eed93a1ee7dd8c65b2f34',\n",
       "  'computed_md5': '060b2020017eed93a1ee7dd8c65b2f34',\n",
       "  'id': 26579171,\n",
       "  'download_url': 'https://ndownloader.figshare.com/files/26579171',\n",
       "  'size': 192},\n",
       " {'is_link_only': False,\n",
       "  'name': 'README.md',\n",
       "  'supplied_md5': '61858c6cc0e6a6d6663a7e4c75bbd88c',\n",
       "  'computed_md5': '61858c6cc0e6a6d6663a7e4c75bbd88c',\n",
       "  'id': 26586554,\n",
       "  'download_url': 'https://ndownloader.figshare.com/files/26586554',\n",
       "  'size': 5422},\n",
       " {'is_link_only': False,\n",
       "  'name': 'data.zip',\n",
       "  'supplied_md5': 'b517383f76e77bd03755a63a8ff83ee9',\n",
       "  'computed_md5': 'b517383f76e77bd03755a63a8ff83ee9',\n",
       "  'id': 26766812,\n",
       "  'download_url': 'https://ndownloader.figshare.com/files/26766812',\n",
       "  'size': 814041183},\n",
       " {'is_link_only': False,\n",
       "  'name': 'get_data.py',\n",
       "  'supplied_md5': '7829028495fd9dec9680ea013474afa6',\n",
       "  'computed_md5': '7829028495fd9dec9680ea013474afa6',\n",
       "  'id': 26766815,\n",
       "  'download_url': 'https://ndownloader.figshare.com/files/26766815',\n",
       "  'size': 4113}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = requests.request(\"GET\", url, headers=headers)\n",
    "data = json.loads(response.text)  # this contains all the articles data, feel free to check it out\n",
    "files = data[\"files\"]             # this is just the data about the files, which is what we want\n",
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boolean-secretary",
   "metadata": {},
   "source": [
    "### Unzipping the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assured-punch",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "files_to_dl = [\"data.zip\"]  # feel free to add other files here\n",
    "for file in files:\n",
    "    if file[\"name\"] in files_to_dl:\n",
    "        os.makedirs(output_directory, exist_ok=True)\n",
    "        urlretrieve(file[\"download_url\"], output_directory + file[\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handled-slovak",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "with zipfile.ZipFile(os.path.join(output_directory, \"data.zip\"), 'r') as f:\n",
    "    f.extractall(output_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "every-strike",
   "metadata": {},
   "source": [
    "### Combining data CSVs using Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "infectious-return",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./figshare/ACCESS-CM2_daily_rainfall_NSW.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fourth-bahamas",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%memit\n",
    "# Shows time that regular python takes to merge file\n",
    "# Join all data together\n",
    "## here we are using a normal python way of merging the data \n",
    "\n",
    "files = glob.glob('./figshare/*.csv') # load all the CSVs\n",
    "df = pd.concat((pd.read_csv(file, index_col=0) # combine them all\n",
    "                .assign(model=re.findall(r'/([^_]*)', file)[0])\n",
    "                for file in files)\n",
    "              )\n",
    "df.to_csv(\"./figshare/combined_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regulated-large",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined = pd.read_csv(\"./figshare/combined_data.csv\")\n",
    "df_combined # combined dataframe "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specified-browser",
   "metadata": {},
   "source": [
    "### Summary of Performance on Different Machines\n",
    "\n",
    "Everyone in the team tried to run the combined files section and we recorded our time consumption and detailed `RAM`, `processor`, and `IF SSD` to check if they are relevant.\n",
    "\n",
    "Below is the summarized table:\n",
    "\n",
    "| Team Member      | RAM |Processor |Is SSD|Time used to combine csv files |Time used to load combined csv to memory |\n",
    "| ----------- | ----------- |----------- |----------- |----------- |----------- |\n",
    "| Rachel      | 16GB of 3733MHz       |2 GHz Quad-Core Intel Core i5       |Yes    |peak memory: 404.39 MiB, increment: 0.05 MiB, CPU times: user 5min 29s, sys: 19.5 s, total: 5min 48s Wall time: 6min       |peak memory: 7112.71 MiB, increment: 3458.57 MiB CPU times: user 58.7 s, sys: 15.7 s, total: 1min 14s Wall time: 1min 23s       |\n",
    "| Daniel   | Text        |Text        |Text        |Text        |Text        |\n",
    "| Santiago   | Text        |Text        |Text        |Text        |Text        |\n",
    "| Rui   | 16 GB 2133 MHz |2.9 GHz Quad-Core Intel Core i7        |Yes        |peak memory: 356.82 MiB, increment: 0.31 MiB, CPU times: user 6min 43s, sys: 19.4 s, total: 7min 3s Wall time: 7min 13s        |peak memory: 2983.91 MiB, increment: 0.19 MiB,CPU times: user 1min, sys: 15 s, total: 1min 15s, Wall time: 1min 21s        |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regulated-split",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined[\"model\"].unique() # print out the unique models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "horizontal-florence",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "du -sh figshare/combined_data.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "injured-serbia",
   "metadata": {},
   "source": [
    "We can see from our combined dataframe that we have 28 unique models to continue our analysis with."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "functional-appeal",
   "metadata": {},
   "source": [
    "### Load the combined CSV to memory and perform a simple EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparative-offering",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%%memit\n",
    "#simple pandas - This is how we do normally ,which means we are loading the entire data to the memory\n",
    "df = pd.read_csv(\"figshare/combined_data.csv\")\n",
    "print(df[\"model\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cordless-humidity",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "looking-greensboro",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking datatypes for columns\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "native-kitchen",
   "metadata": {},
   "source": [
    "We can see that we have object and float64 type columns in our dataframe. This makes sense that `time` and `model` are object types and the rest such as latitude, longitude, and rain are float64 types."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "italian-furniture",
   "metadata": {},
   "source": [
    "### Investigate changing the `dtype` of our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "designing-surname",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The memory usage with the original float64 dtype: {df[['lat_min','lat_max','rain (mm/day)']].memory_usage().sum() / 1e6:.2f} MB\")\n",
    "print(f\"The memory usage after changing to float32 dtype: {df[['lat_min','lat_max','rain (mm/day)']].astype('float32', errors='ignore').memory_usage().sum() / 1e6:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "referenced-swift",
   "metadata": {},
   "source": [
    "### Observation1:\n",
    "> As we switch the data type from `float64` to `float32` the memory usage reduced by a half. This is because `float32` is stored as a 32-bit number, while `float64` is stored as twice as much memory as `float32`. If we have a large amount of data and we don't have a specific requirement on the precision or our original data is not accurate to a certain number of decimal places, `float32` is sufficient enough for us to process the data, which is not only faster but also resource-saving."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fresh-recommendation",
   "metadata": {},
   "source": [
    "### Loading our data in chunks using Pandas and checking the value counts of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contained-suicide",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%%memit\n",
    "counts = pd.Series(dtype=int)\n",
    "for chunk in pd.read_csv(\"figshare/combined_data.csv\", chunksize=10_000_000):\n",
    "    counts = counts.add(chunk[\"model\"].value_counts(), fill_value=0)\n",
    "print(counts.astype(int))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "auburn-collectible",
   "metadata": {},
   "source": [
    "### Observation 2:\n",
    "> By loading in chunks, the value counts are exactly the same as other methods we tried. The peak memory for chunks is significantly lower than that without using chunking method. From our observation, we can conclude that for large-scaled data, if we choose to load in chunk, we can gain the competitive edge for lower memory usage and faster processing speed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amended-authority",
   "metadata": {},
   "source": [
    "### Loading our data using Dask and checking the value counts of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polar-anaheim",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%%memit\n",
    "# Dask\n",
    "df_dask = dd.read_csv('figshare/combined_data.csv')\n",
    "print(df_dask[\"model\"].value_counts().compute())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "changed-education",
   "metadata": {},
   "source": [
    "### Observation3:\n",
    "> So far, Dask is the best pick for us to read large csv file to dataframe. Compared with loading the csv to pandas data frame, when we load the csv file to `dask`, the `peak memory`, `increment memory`, and `wall time` all reduced dramatically for the `value_count()` operation. This is likely because `dask` partitioned the dataframe based on row index and did the calculation in parallel to improve the efficiency. Thus, for large-scale data calculation, we could use dask instead of pandas to improve the code efficiency with minimum syntax change. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indirect-flexibility",
   "metadata": {},
   "source": [
    "### Transfering the dataframe from Python to R using Feather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accomplished-liberia",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%%memit\n",
    "dataset = ds.dataset(\"figshare/combined_data.csv\", format=\"csv\")\n",
    "## this is of arrow table format\n",
    "table = dataset.to_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "virtual-involvement",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# writing in feather format\n",
    "feather.write_feather(table, 'figshare/combined_data.feather')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specialized-finger",
   "metadata": {},
   "source": [
    "### Reason for choosing `feather`\n",
    "> Our team did a comprehensive comparision and research among the four data formats online and testing in practice, in the end `feather` is our best pick for this project scenario. Our reasoning is listed below:\n",
    "\n",
    "> - `Feather` enable us to store and read the data from raw arrow format without much serialization and deserialization which renders it faster (higher I/O speed) than Parquet, although parquet can take less storage memory which is more suitable for long term data storage.\n",
    "    \n",
    "> - Feather is a columnar dataframe which can speed up the data analytics queries. \n",
    "    \n",
    "> - It has the unique competitive advantage for not taking too much memory without the need to unpacking the data before loading to RAM.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surprised-photograph",
   "metadata": {},
   "source": [
    "### Simple EDA in R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latin-cleaners",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "library(tidyr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collective-custody",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%%R\n",
    "library(arrow)\n",
    "start_time <- Sys.time()\n",
    "r_table <- arrow::read_feather(\"figshare/combined_data.feather\")\n",
    "print(class(r_table))\n",
    "library(dplyr)\n",
    "result <- r_table %>% count(model) # showing the different counts of the models \n",
    "end_time <- Sys.time()\n",
    "print(result)\n",
    "print(end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quality-swimming",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "result <- r_table %>% count(time) # showing the different counts of the time\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alien-latex",
   "metadata": {},
   "source": [
    "### Observation From EDA: \n",
    "> The counts for models in R is the same as the counts for models we did previously in python, time to count is faster, which double confirmed the accuracy of EDA analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abstract-pharmacy",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "r_table_d <- r_table %>% drop_na() # drop NA values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bright-morrison",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "r_table_d <- r_table_d %>% rename(rain_mmperday = `rain (mm/day)`) # rename the column for rain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "portable-relations",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "# function to calculate the mode\n",
    "mode <- function(x) {\n",
    "  ux <- unique(x)\n",
    "  ux[which.max(tabulate(match(x, ux)))]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "voluntary-arizona",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "Columns <- c(\"lat_min\", \"lat_max\", \"lon_min\", \"lon_max\", \"rain (mm/perday)\")\n",
    "Mean <- c(mean(r_table_d$lat_min), mean(r_table_d$lat_max), mean(r_table_d$lon_min), mean(r_table_d$lon_max), mean(r_table_d$rain_mmperday))\n",
    "Mode <- c(mode(r_table_d$lat_min), mode(r_table_d$lat_max), mode(r_table_d$lon_min), mode(r_table_d$lon_max), mode(r_table_d$rain_mmperday))\n",
    "Median <- c(median(r_table_d$lat_min), median(r_table_d$lat_max), median(r_table_d$lon_min), median(r_table_d$lon_max), median(r_table_d$rain_mmperday))\n",
    "\n",
    "result <- data.frame(Columns, Mean, Mode, Median)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "turned-consumer",
   "metadata": {},
   "source": [
    "### Observation From Mean, Mode, Mean\n",
    "> The mean and median of location data(`lagtitude` and `longitude`) are very close, which means the data collected are mostly from the same area. The median and mean of `rain` is not quite close which indicates that they are not normally distributed and there might be outliers in the for `rain`. The `mode` are close to the median which means if we randomly sample a value we are likely to sample a value close to the median. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scenic-virginia",
   "metadata": {},
   "source": [
    "### Challenges and difficulties when dealing with large data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pursuant-hotel",
   "metadata": {},
   "source": [
    "> Since we are running the code in the local machine, it took a long time to run. We combatted errors by restarting from scratch if there's anything we want to modify from the start which is frustrating. \n",
    "> Everytime we rerun the notebook we have to delete the downloaded files and redownload it again, which is quite challenging for large-scale data processing.\n",
    "> As we only have one single machine, our EDA was very simple, we can hardly visualize our data or calculate correlation matrices. We were unable to do deep EDA like plots (histograms, correlation matrices, etc.) to show relationships between features because the data was so large and taking a sample of the data would not be ideal."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:525]",
   "language": "python",
   "name": "conda-env-525-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
